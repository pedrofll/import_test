import os
import re
import time
import json
import random
from dataclasses import dataclass
from typing import List, Optional, Tuple
from urllib.parse import urlparse, urlunparse, urljoin
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright

# =========================
# CONFIGURACIÃ“N Y MODELO
# =========================
BASE_URL = "https://www.elcorteingles.es"
AFF_ELCORTEINGLES = os.environ.get("AFF_ELCORTEINGLES", "").strip()
ID_IMPORTACION = f"{BASE_URL}/electronica/moviles-y-smartphones/"

@dataclass
class ProductoECI:
    nombre: str
    memoria: str
    capacidad: str
    version: str
    precio_actual: float
    precio_original: float
    enviado_desde: str
    origen_pagina: str
    img: str
    url_imp: str
    url_exp: str
    url_importada_sin_afiliado: str
    url_sin_acortar_con_mi_afiliado: str
    url_oferta: str
    page_id: str

# =========================
# HELPERS DE EXTRACCIÃ“N
# =========================
RE_GB = re.compile(r"(\d{1,3})\s*GB", re.IGNORECASE)
RE_RAM_PLUS = re.compile(r"(\d{1,3})\s*GB\s*\+\s*(\d{1,4})\s*GB", re.IGNORECASE)

def extraer_ram_rom(titulo: str) -> Optional[Tuple[str, str]]:
    m = RE_RAM_PLUS.search(titulo)
    if m: return f"{m.group(1)}GB", f"{m.group(2)}GB"
    gbs = RE_GB.findall(titulo)
    if len(gbs) >= 2: 
        vals = sorted([int(x) for x in gbs])
        return f"{vals[0]}GB", f"{vals[-1]}GB"
    return None

def parse_productos_from_html(html: str, etiqueta: str) -> List[ProductoECI]:
    soup = BeautifulSoup(html, "html.parser")
    productos = []
    seen_ids = set()
    elements = soup.select('[data-json]')
    
    for el in elements:
        try:
            data = json.loads(el.get('data-json'))
            if "name" not in data or "price" not in data: continue
            pid = data.get("id", str(random.randint(1000, 9999)))
            if pid in seen_ids: continue
            seen_ids.add(pid)
            
            raw_name = data.get("name", "")
            specs = extraer_ram_rom(raw_name)
            if not specs: continue
            
            price_info = data.get("price", {})
            p_act = float(price_info.get("f_price", 0))
            p_org = float(price_info.get("o_price", 0))
            if p_act <= 0: continue
            if p_org <= p_act: p_org = round(p_act * 1.15, 2)
            
            url_raw = urljoin(BASE_URL, data.get("url", ""))
            url_con = f"{url_raw}?aff_id={AFF_ELCORTEINGLES}" if AFF_ELCORTEINGLES else url_raw

            productos.append(ProductoECI(
                nombre=raw_name, memoria=specs[0], capacidad=specs[1], version="Global",
                precio_actual=p_act, precio_original=p_org, enviado_desde="EspaÃ±a",
                origen_pagina=etiqueta, img=data.get("image", ""), url_imp=url_con, 
                url_exp=url_con, url_importada_sin_afiliado=url_raw, 
                url_sin_acortar_con_mi_afiliado=url_con, url_oferta=url_con, page_id=ID_IMPORTACION
            ))
        except: continue
    return productos

# =========================
# MAIN CON PLAYWRIGHT
# =========================
def main():
    print("--- FASE 1: ECI (NAVEGADOR REAL CON BYPASS) ---")
    
    with sync_playwright() as p:
        # Bypass de HTTP/2 y camuflaje de automatizaciÃ³n
        browser = p.chromium.launch(headless=True, args=["--disable-http2", "--disable-blink-features=AutomationControlled"])
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            viewport={"width": 1280, "height": 720}
        )
        page = context.new_page()
        
        # GeneraciÃ³n de URLs corregida
        urls = ["https://www.elcorteingles.es/electronica/moviles-y-smartphones/"]
        for i in range(2, 6):
            urls.append(f"https://www.elcorteingles.es/electronica/moviles-y-smartphones/{i}/")
        
        total = 0
        for i, url in enumerate(urls, start=1):
            print(f"\nðŸ“‚ Procesando PÃ¡gina {i}: {url}")
            try:
                page.goto(url, timeout=90000, wait_until="load")
                time.sleep(random.uniform(5, 8)) # Pausa para renderizado JS
                
                html = page.content()
                if "Access Denied" in html:
                    print("      â›” Error: Akamai ha bloqueado la IP del servidor.")
                    continue
                    
                prods = parse_productos_from_html(html, str(i))
                print(f"      âœ… Encontrados: {len(prods)}")
                total += len(prods)
                
                for p in prods[:2]: # Log de ejemplo
                    print(f"      ðŸ“± {p.nombre} | {p.precio_actual}â‚¬")
            except Exception as e:
                print(f"      âŒ Error en pÃ¡gina {i}: {str(e)[:100]}")
        
        browser.close()
        print(f"\nðŸ“‹ TOTAL ESCANEADOS: {total}")

if __name__ == "__main__":
    main()
